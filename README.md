# 90 Days to Senior Data Engineer and Data Scientist

Nombre: Javier
Rol Actual: Data Engineer en Visible (Unicomer Group)
Objetivo: Especialización en Ingeniería de Datos Senior y Ciencia de Datos.

Este repositorio contiene el registro técnico del plan intensivo de 20 semanas orientado a la escalabilidad, eficiencia de memoria y arquitectura en la nube.

## Stack Tecnologico
- Lenguaje: Python 3.12+ (Enfoque en eficiencia de memoria y generadores)
- Nube: Google Cloud Platform (BigQuery, Dataproc, Dataflow)
- Herramientas: Docker, dbt, Apache Spark, Airflow
- Entorno: Virtualenv (venv) para gestion de dependencias

## Roadmap de Aprendizaje

### FASE 1: Fundamentos de Ingenieria de Software
- Semana 1: Python Avanzado
    - Lunes: Generadores (yield) vs Listas. Gestion de RAM.
    - Martes: Decoradores, Context Managers y Programacion Funcional.
    - Miercoles: Programacion Orientada a Objetos (POO) aplicada a ETL.
    - Jueves: Asyncio y Concurrencia.
- Semana 2: Testing y Calidad de Software.
- Semana 3: Dockerizacion de Procesos.
- Semana 4: Automatización con CI/CD (GitHub Actions).

### FASE 2: Bases de Datos y Modelado
- Semana 5: SQL Avanzado (Window Functions y CTEs).
- Semana 6: Optimizacion de Bases de Datos e Indices.
- Semana 7: Modelado Dimensional (Kimball).
- Semana 8: Data Lake Formats (Parquet, Delta Lake).

## Estructura del Proyecto
- /01-Software-Engineering: Logica de programacion y patrones de diseño.
- /02-Databases-Modeling: Implementaciones de SQL y esquemas de datos.
- /03-Big-Data-Transformation: Procesamiento distribuido con Spark y dbt.
- /04-Cloud-Infrastructure: Infraestructura como codigo y orquestacion.

---
Notas de Lunes (Semana 1):
Implementacion de generadores para la optimización de memoria en pipelines de datos.
Notas de Martes (Semana 1):
Implementacion de decoradores para monitoreo de ejecucion y context managers para asegurar el cierre de recursos en pipelines de datos.
